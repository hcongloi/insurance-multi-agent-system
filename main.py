# main.py
import streamlit as st
from langchain_core.messages import HumanMessage, AIMessage
import time  # ThÃªm Ä‘á»ƒ mÃ´ phá»ng loading time hoáº·c cÃ¡c animations nhá»

# Import create_multi_agent_workflow tá»« file langgraph_workflow.py
from langgraph_workflow import create_multi_agent_workflow

# Sá»­ dá»¥ng st.cache_resource Ä‘á»ƒ khá»Ÿi táº¡o LangGraph app má»™t láº§n duy nháº¥t.
# Äiá»u nÃ y ráº¥t quan trá»ng Ä‘á»ƒ trÃ¡nh khá»Ÿi táº¡o láº¡i cÃ¡c model vÃ  vectorstore trÃªn má»—i láº§n rerun cá»§a Streamlit.
@st.cache_resource
def get_langgraph_app():
    return create_multi_agent_workflow()

app = get_langgraph_app()

# Cáº¥u hÃ¬nh trang Streamlit
st.set_page_config(page_title="Multi-Agent Insurance Assistant", page_icon="ğŸ¤–", layout="wide")
st.title("ğŸ¤– Multi-Agent Insurance Assistant")
st.caption("Powered by LangChain 1.0.5 & Google Gemini 1.5 Flash")

# Khá»Ÿi táº¡o session state náº¿u chÆ°a cÃ³
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "agent_execution_log" not in st.session_state:
    st.session_state.agent_execution_log = []

def get_response(user_query: str) -> str:
    """
    Thá»±c thi workflow Ä‘a tÃ¡c tá»­ vÃ  stream káº¿t quáº£.
    Ghi log cÃ¡c bÆ°á»›c trung gian vÃ o st.session_state.agent_execution_log.
    Tráº£ vá» pháº£n há»“i cuá»‘i cÃ¹ng dÆ°á»›i dáº¡ng chuá»—i.
    """
    st.session_state.agent_execution_log = []  # Äáº·t láº¡i log cho má»—i truy váº¥n má»›i
    
    # Táº¡o tráº¡ng thÃ¡i ban Ä‘áº§u cho workflow. Quan trá»ng lÃ  pháº£i lÃ  má»™t dict má»›i má»—i láº§n.
    inputs = {
        "input": user_query,
        "chat_history": [],  # Truyá»n chat_history rá»—ng vÃ¬ AgentState cÃ³ Annotated[List[BaseMessage], operator.add]
        "customer_info_result": "",
        "lead_info_result": "",
        "kb_info_result": "",
        "customer_profile": {}, 
        "available_products_kb": "", 
        "recommendation_result": "", 
        "final_response": "",
        "intermediate_steps": [],
        "is_recommendation_flow": False,
        "error_message": "",
        "router_decision": ""  # Khá»Ÿi táº¡o router_decision
    }
    
    full_response = ""
    last_state = None  # ThÃªm biáº¿n Ä‘á»ƒ lÆ°u state cuá»‘i cÃ¹ng
    start_time = time.time()  # Báº¯t Ä‘áº§u tÃ­nh thá»i gian pháº£n há»“i
    
    try:
        # Stream cÃ¡c bÆ°á»›c thá»±c thi Ä‘á»ƒ theo dÃµi
        for s in app.stream(inputs, stream_mode="updates"):
            # stream_mode="updates" tráº£ vá» dict vá»›i key lÃ  tÃªn node vÃ  value lÃ  state updates
            for key, value in s.items():
                # LÆ°u state cuá»‘i cÃ¹ng tá»« má»—i update
                if isinstance(value, dict):
                    if last_state is None:
                        last_state = value.copy()
                    else:
                        last_state.update(value)
                
                # Ghi log cho router node
                if key == "router_node":
                    router_decision = value.get("router_decision") 
                    if router_decision:
                        st.session_state.agent_execution_log.append(f"ğŸ”„ **Orchestrator Routing:** Decided to use `{router_decision}`")
                
                # Ghi log cho flag khuyáº¿n nghá»‹
                elif key == "set_recommendation_flag":
                    st.session_state.agent_execution_log.append(f"ğŸš© **Orchestrator Flag:** `is_recommendation_flow` set to `True`.")
                
                # Ghi log cho cÃ¡c agent vÃ  node khÃ¡c
                elif key.endswith("_agent_node") or key == "run_recommendation_node" or key == "prepare_kb_query_for_recommendation":
                    agent_name = key.replace("_agent_node", "").replace("run_", "").replace("_", " ").title().replace("Prep", " Prep")

                    # Ghi log cÃ¡c bÆ°á»›c trung gian cá»§a agent (React agent)
                    if value.get("intermediate_steps"):
                        for action, observation in value["intermediate_steps"]:
                            st.session_state.agent_execution_log.append(f"â¡ï¸ **{agent_name} Action:** `{action.tool}({action.tool_input})`")
                            display_observation = str(observation)
                            if len(display_observation) > 100:
                                display_observation = display_observation[:97] + "..."
                            st.session_state.agent_execution_log.append(f"âœ… **{agent_name} Observation:** `{display_observation}`")
                    
                    # Ghi log káº¿t quáº£ Ä‘áº·c trÆ°ng cá»§a tá»«ng agent
                    if value.get("customer_info_result"):
                         st.session_state.agent_execution_log.append(f"ğŸ“„ **{agent_name} Result:** Customer Info: {value['customer_info_result'].splitlines()[0]}...")
                         if value.get("customer_profile"):
                             st.session_state.agent_execution_log.append(f"ğŸ‘¤ **{agent_name} Profile:** {value['customer_profile'].get('name', 'Unknown')} (ID: {value['customer_profile'].get('id', 'N/A')}) loaded.")
                    elif value.get("lead_info_result"):
                         st.session_state.agent_execution_log.append(f"ğŸ“„ **{agent_name} Result:** Leads: {value['lead_info_result'].splitlines()[0]}...")
                    elif value.get("kb_info_result"):
                         st.session_state.agent_execution_log.append(f"ğŸ“„ **{agent_name} Result:** KB Info: {value['kb_info_result'].splitlines()[0]}...")
                         if value.get("available_products_kb"):
                             st.session_state.agent_execution_log.append(f"ğŸ“š **{agent_name} Products:** Knowledge base content loaded for recommendations.")
                    elif value.get("recommendation_result"):
                         st.session_state.agent_execution_log.append(f"ğŸŒŸ **{agent_name} Result:** Recommendations generated.")
                    elif key == "prepare_kb_query_for_recommendation":
                         st.session_state.agent_execution_log.append(f"ğŸ“¦ **{agent_name}:** Preparing KB query for recommendation.")

                # Ghi log khi response cuá»‘i cÃ¹ng Ä‘Æ°á»£c finalize
                elif key == "final_response_node":
                    if value.get("final_response"):
                        st.session_state.agent_execution_log.append(f"âœ¨ **Orchestrator: Finalizing Response**")
                
                # Kiá»ƒm tra lá»—i tá»« báº¥t ká»³ node nÃ o
                if value.get("error_message"): 
                    st.session_state.agent_execution_log.append(f"âŒ **Error from {key}:** {value['error_message']}")
        
        # Láº¥y final_response tá»« state cuá»‘i cÃ¹ng
        if last_state:
            full_response = last_state.get('final_response', "No final response generated.")
            if last_state.get('error_message') and not full_response:
                full_response = f"âš ï¸ An internal error occurred: {last_state['error_message']}"
            elif last_state.get('error_message'):
                full_response = f"âš ï¸ An internal error occurred: {last_state['error_message']}\n\n{full_response}"
        else:
            full_response = "No response was generated. Please try again."
            
    except Exception as e:
        # Xá»­ lÃ½ cÃ¡c lá»—i nghiÃªm trá»ng xáº£y ra ngoÃ i cÃ¡c node cá»¥ thá»ƒ
        full_response = f"An unexpected workflow error occurred: {e}. Please check the logs or try rephrasing your query."
        st.session_state.agent_execution_log.append(f"âŒ **Critical Workflow Error**: {e}")
    
    end_time = time.time()
    response_time = end_time - start_time
    st.session_state.agent_execution_log.append(f"â±ï¸ **Response Time:** {response_time:.2f} seconds")

    return full_response


# --- Streamlit UI Layout ---
# Chia layout thÃ nh hai cá»™t: chat vÃ  log
col1, col2 = st.columns([0.7, 0.3])

with col1:
    # Hiá»ƒn thá»‹ lá»‹ch sá»­ chat
    for message in st.session_state.chat_history:
        if isinstance(message, HumanMessage):
            with st.chat_message("user"):
                st.markdown(message.content)
        elif isinstance(message, AIMessage):
            with st.chat_message("assistant"):
                st.markdown(message.content)

    # Ã” nháº­p liá»‡u cho ngÆ°á»i dÃ¹ng.
    # st.chat_input tráº£ vá» giÃ¡ trá»‹ khi user nháº¥n Enter
    user_query = st.chat_input("Ask about customers, leads, or insurance policies...")
    
    # Xá»­ lÃ½ input náº¿u cÃ³
    if user_query:
        # ThÃªm tin nháº¯n cá»§a ngÆ°á»i dÃ¹ng vÃ o lá»‹ch sá»­ chat
        st.session_state.chat_history.append(HumanMessage(content=user_query))
        
        # Xá»­ lÃ½ truy váº¥n vÃ  láº¥y pháº£n há»“i AI
        with st.spinner("Processing your request..."):
            ai_response = get_response(user_query)
        
        # ThÃªm pháº£n há»“i AI vÃ o lá»‹ch sá»­ chat
        st.session_state.chat_history.append(AIMessage(content=ai_response))
        
        # Rerun Ä‘á»ƒ cáº­p nháº­t UI vÃ  clear input
        st.rerun()


with col2:
    st.header("ğŸ” Agent Execution Log")
    # Hiá»ƒn thá»‹ log ngÆ°á»£c láº¡i Ä‘á»ƒ cÃ¡c log má»›i nháº¥t náº±m trÃªn cÃ¹ng
    if st.session_state.agent_execution_log:
        for log_entry in reversed(st.session_state.agent_execution_log): 
            st.markdown(log_entry)
    else:
        st.info("No agent activity yet. Ask a question to see the execution flow!")
    
    # NÃºt xÃ³a log
    if st.button("ğŸ—‘ï¸ Clear Log", key="clear_log_button"):
        st.session_state.agent_execution_log = []
        st.rerun()

# --- Thanh sidebar vá»›i cÃ¡c cÃ¢u truy váº¥n vÃ­ dá»¥ ---
st.sidebar.header("ğŸ“ Example Queries")
example_queries = {
    "Customer Queries": [
        "Find customer with email john@example.com",
        "Find customer John Smith",
        "Tell me about CUST003's policies."
    ],
    "Lead Queries": [
        "Show me qualified leads in Texas",
        "Find leads with score above 80 interested in auto insurance",
        "Are there any new leads interested in life insurance?"
    ],
    "Knowledge Queries": [
        "What is comprehensive auto insurance?",
        "What is an insurance deductible?",
        "What is a premium?",
        "Explain different types of life insurance.",
        "Tell me about car warranties?"
    ],
    "Recommendation Workflows": [
        "Find customer John Smith and recommend insurance products based on his profile",
        "Show me customer John Smith's current policies and recommend additional coverage options",
        "Recommend coverage for John Smith",
        "Find customer Emily Brown and recommend insurance products based on her profile",
        "Recommend products for non_existent@example.com",
    ],
    "General Fallback": [
        "Can you tell me a joke?",
        "Hello"
    ]
}

for category, queries in example_queries.items():
    st.sidebar.subheader(category)
    for query in queries:
        if st.sidebar.button(query, key=f"sidebar_query_{query}"):
            # Khi má»™t nÃºt sidebar Ä‘Æ°á»£c nháº¥n, thÃªm truy váº¥n vÃ o lá»‹ch sá»­ chat
            st.session_state.chat_history.append(HumanMessage(content=query))
            
            # Xá»­ lÃ½ truy váº¥n vÃ  láº¥y pháº£n há»“i AI
            with st.spinner("Processing..."):
                ai_response = get_response(query)
            
            # ThÃªm pháº£n há»“i AI vÃ o lá»‹ch sá»­ chat
            st.session_state.chat_history.append(AIMessage(content=ai_response))
            st.rerun()  # Gá»i rerun Ä‘á»ƒ cáº­p nháº­t UI sau khi cÃ³ pháº£n há»“i

st.sidebar.markdown("---")
if st.sidebar.button("ğŸ—‘ï¸ Clear Chat History", key="clear_chat_button"):
    st.session_state.chat_history = []
    st.session_state.agent_execution_log = []
    st.rerun()